{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper code adapted from filterpy and https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/kf_book/mkf_internal.py\n",
    "\n",
    "def covariance_ellipse(P, deviations=1):\n",
    "    \"\"\"\n",
    "    Returns a tuple defining the ellipse representing the 2 dimensional\n",
    "    covariance matrix P.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    P : nd.array shape (2,2)\n",
    "       covariance matrix\n",
    "\n",
    "    deviations : int (optional, default = 1)\n",
    "       # of standard deviations. Default is 1.\n",
    "\n",
    "    Returns (angle_radians, width_radius, height_radius)\n",
    "    \"\"\"\n",
    "\n",
    "    U, s, _ = sp.linalg.svd(P)\n",
    "    orientation = math.atan2(U[1, 0], U[0, 0])\n",
    "    width = deviations * math.sqrt(s[0])\n",
    "    height = deviations * math.sqrt(s[1])\n",
    "\n",
    "    if height > width:\n",
    "        raise ValueError('width must be greater than height')\n",
    "\n",
    "    return (orientation, width, height)\n",
    "\n",
    "def _std_tuple_of(var=None, std=None, interval=None):\n",
    "    \"\"\"\n",
    "    Convienence function for plotting. Given one of var, standard\n",
    "    deviation, or interval, return the std. Any of the three can be an\n",
    "    iterable list.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>>_std_tuple_of(var=[1, 3, 9])\n",
    "    (1, 2, 3)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if std is not None:\n",
    "        if np.isscalar(std):\n",
    "            std = (std,)\n",
    "        return std\n",
    "\n",
    "\n",
    "    if interval is not None:\n",
    "        if np.isscalar(interval):\n",
    "            interval = (interval,)\n",
    "\n",
    "        return np.norm.interval(interval)[1]\n",
    "\n",
    "    if var is None:\n",
    "        raise ValueError(\"no inputs were provided\")\n",
    "\n",
    "    if np.isscalar(var):\n",
    "        var = (var,)\n",
    "    return np.sqrt(var)\n",
    "\n",
    "def plot_covariance(\n",
    "        mean, cov=None, variance=1.0, std=None, interval=None,\n",
    "        ellipse=None, title=None, axis_equal=True,\n",
    "        show_semiaxis=False, show_center=True,\n",
    "        facecolor=None, edgecolor=None,\n",
    "        fc='none', ec='#004080',\n",
    "        alpha=1.0, xlim=None, ylim=None,\n",
    "        ls='solid'):\n",
    "    from matplotlib.patches import Ellipse\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if cov is not None and ellipse is not None:\n",
    "        raise ValueError('You cannot specify both cov and ellipse')\n",
    "\n",
    "    if cov is None and ellipse is None:\n",
    "        raise ValueError('Specify one of cov or ellipse')\n",
    "\n",
    "    if facecolor is None:\n",
    "        facecolor = fc\n",
    "\n",
    "    if edgecolor is None:\n",
    "        edgecolor = ec\n",
    "\n",
    "    if cov is not None:\n",
    "        ellipse = covariance_ellipse(cov)\n",
    "\n",
    "    if axis_equal:\n",
    "        plt.axis('equal')\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    angle = np.degrees(ellipse[0])\n",
    "    width = ellipse[1] * 2.\n",
    "    height = ellipse[2] * 2.\n",
    "\n",
    "    std = _std_tuple_of(variance, std, interval)\n",
    "    for sd in std:\n",
    "        e = Ellipse(xy=mean, width=sd*width, height=sd*height, angle=angle,\n",
    "                    facecolor=facecolor,\n",
    "                    edgecolor=edgecolor,\n",
    "                    alpha=alpha,\n",
    "                    lw=2, ls=ls)\n",
    "        ax.add_patch(e)\n",
    "    x, y = mean\n",
    "    if show_center:\n",
    "        plt.scatter(x, y, marker='+', color=edgecolor, label=\"Filter Guess\")\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    if show_semiaxis:\n",
    "        a = ellipse[0]\n",
    "        h, w = height/4, width/4\n",
    "        plt.plot([x, x+ h*np.cos(a+np.pi/2)], [y, y + h*np.sin(a+np.pi/2)])\n",
    "        plt.plot([x, x+ w*np.cos(a)], [y, y + w*np.sin(a)])\n",
    "\n",
    "\n",
    "def plot_track_ellipses(ps, cov, title):\n",
    "    plt.title(title)\n",
    "\n",
    "    for i,p in enumerate(cov):\n",
    "        plot_covariance(\n",
    "              (i, ps[i]), cov=p, variance=1,\n",
    "               axis_equal=False, ec='g', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Simulation\n",
    "Let's imagine that we want to track a moving target in the world (a runaway Neato perhaps). We'll create a simulator that gives us the Neato's 1D position according to a process variance. It will also give us a noisy observation of our Neato's position in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_realworld_neato(sensor_var, process_var, vel=1.0, step=1, dt=1.):\n",
    "    \"\"\"Simulates the movement of a Neato and measurement in the world.\n",
    "    Input: \n",
    "        sensor_var\n",
    "        process_var\n",
    "        vel (float): velocity of the bot\n",
    "        step (int): number of simulation snapshots\n",
    "        dt (float): time delta between simulation snapshots\n",
    "    Return:\n",
    "        xs (array(float)): real positions\n",
    "        zs (array(float)): observed positions\n",
    "    \"\"\"\n",
    "    x = 0.  # initial position\n",
    "    sensor_std = math.sqrt(sensor_var)  # compute sensor standard deviation from variance\n",
    "    process_std = math.sqrt (process_var)  # compute process standard deviation from variance\n",
    "    xs, zs = [] ,[]\n",
    "    for i in range(step):\n",
    "        v = vel + (np.random.randn() * process_std)\n",
    "        x += v * dt  # simple velocity based update\n",
    "        xs.append(x)\n",
    "        zs.append(x + np.random.randn() * sensor_std)  # noise corrupted observation\n",
    "    return np.array(xs), np.array(zs)\n",
    "\n",
    "xs, zs = simulate_realworld_neato(0.2, 0.1, vel=1., step=10, dt=0.5)\n",
    "plt.plot(xs, marker=\".\", ms=10, label=\"Real Path\")\n",
    "plt.plot(zs, linestyle=\"--\", marker=\"*\", ms=10, label=\"Observations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Our Filter Components\n",
    "Kalman filtering is just a Bayesian filter, where everything is a Gaussian (yay). Like in any Bayesian filter, there are two key steps: Prediction and Update. We're going to define each of these for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "#### Defining the State Variable\n",
    "The _state_ of our world is our Neato's position and velocity. We will use the notation $\\mathbf{x} = [x, \\dot{x}]^T$ to represent the state of our Neato, where the first term is our position, and the second term is our velocity.\n",
    "\n",
    "#### Designing State Covariance\n",
    "Since we're representing everything as a Gaussian, we need to define the variance we associate with our state position (basically, how uncertain we are about our pose). Since we have a two dimensional system, our covariance will be a 2x2 matrix:\n",
    "\n",
    "$$\\mathbf{P} = \\begin{bmatrix}\n",
    "\\sigma_{xx} & \\sigma_{x\\dot{x}}\\\\\n",
    "\\sigma{\\dot{x}{x}} & \\sigma{\\dot{x}\\dot{x}}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "where the diagonal is the variance in each variable, and the off-diagonal components are the covariances between variables. In practice, we might get these variables by knowing a little something about our Neato or our world -- we may set $\\sigma_{xx}$ to be very small if we have good position estimate about our Neato...or large if we don't. Same for velocity. We may know that our position uncertainty may be a function of how fast the Neato moves. This matrix captures these elements.\n",
    "\n",
    "#### The Process Model (AKA the \"Prediction\" Step)\n",
    "This is the \"motion\" or \"action\" model of our world -- what our expected transitions are. Since we are tracking a Neato moving in 1D, we might use the following model:\n",
    "\n",
    "$$x_t = v\\Delta t + x_{t-1}$$ \n",
    "\n",
    "Expressing this in terms of the elements of our state:\n",
    "\n",
    "$$\\mathbf{x}_t = \\mathbf{F}\\mathbf{x}_{t-1}$$\n",
    "$$\\begin{bmatrix}\n",
    "x_t \\\\\n",
    "\\dot{x_t}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & \\Delta t\\\\\n",
    "0 & 1 \\end{bmatrix} \\begin{bmatrix}\n",
    "x_{t-1} \\\\\n",
    "\\dot{x_{t-1}}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "#### The Process Noise\n",
    "Our process may have some noise associated with it as well. We can represent this as a covariance matrix as well, and it is _typical_ that this is assumed to be white noise.\n",
    "\n",
    "$$\\mathbf{Q} = \\begin{bmatrix}\n",
    "(0.5v_q\\Delta t^2)^2 & 0.5v_q\\Delta t^2\\\\\n",
    "0.5v_q\\Delta t^2 & v_q\\Delta t^2\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "where $v_q$ is the variance in the noise.\n",
    "\n",
    "#### Applying our Prediction\n",
    "We can now perform a prediction! Recall that our prediction is two steps: advancing our state according to our process model, and advancing our uncertainty according to our process model and process noise:\n",
    "\n",
    "$$\\mathbf{x}_t = \\mathbf{F}\\mathbf{x}_{t-1}$$\n",
    "$$\\mathbf{P}_t = \\mathbf{F}\\mathbf{P}_t\\mathbf{F}^T + \\mathbf{Q}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Q(dt, var):\n",
    "    \"\"\"Returns a white noise model Q according to dt and var\"\"\"\n",
    "    return np.array([[(0.5*var*dt**2)**2, 0.5*var*dt**2],[0.5*var*dt**2, var*dt**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, P, F, Q):\n",
    "    \"\"\"Returns a prediction update for pose and pose covariance according to the process model\"\"\"\n",
    "    # Your code here! \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your prediction on a quick sample case\n",
    "dt = 1.\n",
    "x = np.array([1., 0.5]).T\n",
    "P = np.array([[500, 0],\n",
    "              [0, 49]])\n",
    "F = np.array([[1, dt],\n",
    "              [0, 1]])\n",
    "Q = get_Q(dt, 1.)\n",
    "\n",
    "xt_sol = np.array([1.5, 0.5]).T\n",
    "Pt_sol = np.array([[549.25, 49.5],[49.5, 50.]])\n",
    "\n",
    "x1, P1 = predict(x, P, F, Q)\n",
    "print(x1[0] == xt_sol[0] and x1[1] == xt_sol[1])\n",
    "print(P1[0][0] == Pt_sol[0][0] and P1[1][0] == Pt_sol[1][0] and P1[0][1] == Pt_sol[0][1] and P1[1][1] == Pt_sol[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update\n",
    "\n",
    "So we can now forward simulate our world, so let's use measurements of our new state to (hopefully) reduce our uncertainty. For this, we need to design our measurement function:\n",
    "\n",
    "$$\\mathbf{y} = \\mathbf{z} - \\mathbf{H}\\mathbf{x}$$\n",
    "\n",
    "where this is the _residual function_ where $y$ is our residual between our real observation $z$ and our hypothesized observation according to the state of our world $x$ and a sensor model $H$.\n",
    "\n",
    "In the case of our simple world, we'll assume we can only measure position; velocity is _hidden_ from us, thus $\\mathbf{H} = [1, 0]$.\n",
    "\n",
    "### A Noisy Measurement\n",
    "Our actual observation $z$ we assume is corrupted by noise of some kind again. We call this variable $\\mathbf{R}$. Since we only have 1 measurement (position) we only have 1 variance to represent here: $\\mathbf{R} = [\\sigma_z^2]$. Note that if we had a measurement for velocity, this would turn into a 2x2 covariance matrix!!\n",
    "\n",
    "### Kalman Gain\n",
    "Our updating step requires us to set a gain for our system. We can think of the Kalman gain as being a way to put our ultimate estimate somewhere between our predicted location, and our residual location. It's computed by considering our observation characteristics and our estimate of process covariance:\n",
    "\n",
    "$$K_t = P_tH^T(HP_tH^T + R)^{-1}$$\n",
    "\n",
    "### Putting it Together\n",
    "Finally, our update step is going to update our estimated location based on our predicted guess + our weighted residual; and our estimated covariance is going to be updated weighted by our Kalman gain and measurement function:\n",
    "\n",
    "$$x_t = x_{t-1} + K_t(z_t - Hx_{t-1})$$\n",
    "$$P_t = (I - K_tH)P_{t-1}$$\n",
    "\n",
    "where $I$ is the identity matrix. Let's implement!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x, P, z, H, R):\n",
    "    \"\"\"Performs an update to x, P given observation z according to measurement model H and measurement noise R\"\"\"\n",
    "    # Your code here!\n",
    "    # hint...you may find the scipy linalg \"inv\" function useful here!\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your update with a simple test case\n",
    "dt = 1.\n",
    "x = np.array([1., 0.5]).T\n",
    "z = np.array([1.])  # the exact measurement of the real world...should reduce our uncertainty in position\n",
    "P = np.array([[500, 0],\n",
    "              [0, 49]])\n",
    "F = np.array([[1, dt],\n",
    "              [0, 1]])\n",
    "Q = get_Q(dt, 1.)\n",
    "H = np.array([[1., 0.]])\n",
    "R = np.array([[10]])\n",
    "\n",
    "xt_sol = np.array([1., 0.5]).T\n",
    "Pt_sol = np.array([[9.80392157, 0.],[0, 49.]])\n",
    "\n",
    "x1, P1 = update(x, P, z, H, R)\n",
    "\n",
    "print(x1[0] == xt_sol[0] and x1[1] == xt_sol[1])\n",
    "print(P1[0][0]-Pt_sol[0][0] < 0.0001 and P1[1][0] == Pt_sol[1][0] and P1[0][1] == Pt_sol[0][1] and P1[1][1] == Pt_sol[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Filtering -- A Recursive Algorithm\n",
    "Ok! Let's implement this for our Neato tracking world. For every step of our simulation, we'll get a new observation. We'll want to perform a prediction step, then an update step based on that observation. Let's give it a go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our models\n",
    "steps = 50\n",
    "dt = 1\n",
    "robot_vel = 2.0\n",
    "sensor_var = 100.\n",
    "process_var = 0.1\n",
    "\n",
    "x = np.array([10., 4.5]).T  # initial guess of state\n",
    "P = np.diag([500., 49.])  # initial variance on state variables\n",
    "F = np.array([[1, dt],\n",
    "              [0, 1]])  # process model\n",
    "Q = get_Q(dt, var=0.01)#process_var)  # process noise\n",
    "H = np.array([[1., 0.]])  # measurement model\n",
    "R = np.array([[10.]])#sensor_var]])  # measurement variance\n",
    "\n",
    "true_poses, observations = simulate_realworld_neato(sensor_var, process_var, vel=robot_vel, step=steps, dt=dt)\n",
    "x_filter = []\n",
    "P_filter = []\n",
    "\n",
    "\n",
    "# Iterate through observations\n",
    "for z in observations:\n",
    "    x_predict, P_predict = predict(x, P, F, Q)\n",
    "    x, P = update(x_predict, P_predict, z, H, R)\n",
    "    x_filter.append(x)\n",
    "    P_filter.append(P)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "fig = plt.figure()\n",
    "xf, Pf = np.array(x_filter), np.array(P_filter)\n",
    "plt.plot(true_poses, marker=\".\", ms=10, label=\"True Path\")\n",
    "plt.plot(observations, marker=\"*\", ms=10, lw=0, label=\"Observations\")\n",
    "plt.plot(xf[:,0], lw=1, label=\"Filter Estimate\")\n",
    "plot_track_ellipses(xf[:,0], Pf, title=\"track\")\n",
    "plt.legend([\"True Path\", \"Observations\", \"Filter Guess\"])\n",
    "plt.gcf().set_size_inches(12, 6)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the velocity estimate\n",
    "fig = plt.figure()\n",
    "plt.plot(np.ones_like(xf[:,1])*robot_vel, label=\"True Velocity\")\n",
    "plt.plot(xf[:,1], lw=5, label=\"Filter Estimate Velocity\")\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches(12, 6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the covariance over time\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(Pf[:,0,0], lw=5, label=\"Position Variance\")\n",
    "ax[0].set_title(\"Position Variance\")\n",
    "ax[1].plot(Pf[:,1,1], lw=5, label=\"Velocity Variance\")\n",
    "ax[1].set_title(\"Velocity Variance\")\n",
    "fig.set_size_inches(12, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
